{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hk_resnet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWXz_N3iqUJh",
        "outputId": "e001a19b-a1b8-4f3c-de38-c4b01d4fee16"
      },
      "source": [
        "!pip install git+https://github.com/deepmind/dm-haiku\n",
        "!pip install optax"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/deepmind/dm-haiku\n",
            "  Cloning https://github.com/deepmind/dm-haiku to /tmp/pip-req-build-hqx0kbqk\n",
            "  Running command git clone -q https://github.com/deepmind/dm-haiku /tmp/pip-req-build-hqx0kbqk\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.5.dev0) (0.12.0)\n",
            "Collecting jmp>=0.0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/5c/1482f4a4a502e080af2ca54d7f80a60b5d4735f464c151666d583b78c226/jmp-0.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.5.dev0) (1.19.5)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.5.dev0) (0.8.9)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.5.dev0) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.7.1->dm-haiku==0.0.5.dev0) (1.15.0)\n",
            "Building wheels for collected packages: dm-haiku\n",
            "  Building wheel for dm-haiku (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dm-haiku: filename=dm_haiku-0.0.5.dev0-cp37-none-any.whl size=553003 sha256=057e07bbbf1371edd36ca02e258d81297f1ad6228c43f3649d60853f9c38a871\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wy6itgwv/wheels/97/0f/e9/17f34e377f8d4060fa88a7e82bee5d8afbf7972384768a5499\n",
            "Successfully built dm-haiku\n",
            "Installing collected packages: jmp, dm-haiku\n",
            "Successfully installed dm-haiku-0.0.5.dev0 jmp-0.0.2\n",
            "Collecting optax\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/7a/6259edd319ee7fa94dd23c54f15eff667f599d179e889af90fe0c204612c/optax-0.0.6-py3-none-any.whl (96kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 10.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from optax) (0.1.66+cuda110)\n",
            "Requirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.7/dist-packages (from optax) (0.2.13)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from optax) (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from optax) (1.19.5)\n",
            "Collecting chex>=0.0.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/b9/445eb59ec23249acffc5322c79b07e20b12dbff45b9c1da6cdae9e947685/chex-0.0.7-py3-none-any.whl (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->optax) (1.4.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->optax) (1.12)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (3.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.7.1->optax) (1.15.0)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.11.1)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.1.6)\n",
            "Installing collected packages: chex, optax\n",
            "Successfully installed chex-0.0.7 optax-0.0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGGkgkglxQeh",
        "outputId": "d0a65c6e-468c-4bae-fd71-0a824fd1564c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/chao1224/BadGlobalMinima"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'BadGlobalMinima'...\n",
            "remote: Enumerating objects: 29, done.\u001b[K\n",
            "remote: Counting objects:  11% (1/9)\u001b[K\rremote: Counting objects:  22% (2/9)\u001b[K\rremote: Counting objects:  33% (3/9)\u001b[K\rremote: Counting objects:  44% (4/9)\u001b[K\rremote: Counting objects:  55% (5/9)\u001b[K\rremote: Counting objects:  66% (6/9)\u001b[K\rremote: Counting objects:  77% (7/9)\u001b[K\rremote: Counting objects:  88% (8/9)\u001b[K\rremote: Counting objects: 100% (9/9)\u001b[K\rremote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 29 (delta 1), reused 4 (delta 0), pack-reused 20\u001b[K\n",
            "Unpacking objects: 100% (29/29), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8Rd2iLTJ7zH"
      },
      "source": [
        "import haiku as hk\n",
        "import optax\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import tree\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from typing import NamedTuple\n",
        "\n",
        "AUGMENTATION = True\n",
        "ADVERSARIAL = True"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acZdNJ3NzyZL"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzIlxFxNz8Fx"
      },
      "source": [
        "key1 = jax.random.PRNGKey(0)\n",
        "\n",
        "if (ADVERSARIAL):\n",
        "    y_train = jax.random.permutation(key1, y_train)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssqTD0sAVoe6"
      },
      "source": [
        "# (train_ds, test_ds), ds_info = tfds.load('cifar10', \n",
        "#                                           split=['train', 'test'], \n",
        "#                                           shuffle_files=True, \n",
        "#                                           with_info=True)\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices({\"image\": x_train, \"label\": y_train})\n",
        "\n",
        "\n",
        "# fig = tfds.show_examples(train_ds, ds_info)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZFLinvj4GTd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oycD-X4jVIrw"
      },
      "source": [
        "def preprocess(example):\n",
        "    image, label = example['image'], example['label']\n",
        "\n",
        "    # Data augmentation\n",
        "    image = tf.image.resize_with_crop_or_pad(image, 170, 170) # Adiciona 10 pixels\n",
        "    image = tf.image.random_crop(image, size=[160, 160, 3]) # Corta de volta para 160\n",
        "    image = tf.image.random_flip_left_right(image) \n",
        "\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    return {'image': image, 'label': label}"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKgYVQkTWgbP",
        "outputId": "050125f9-5adb-4f22-e15d-4eb1733fdf68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "if (AUGMENTATION):\n",
        "    train_ds = train_ds.map(\n",
        "        preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "train_ds = train_ds.cache()\n",
        "train_ds = train_ds.shuffle(ds_info.splits['train'].num_examples)\n",
        "train_ds = train_ds.batch(128)\n",
        "ds_numpy = tfds.as_numpy(train_ds)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"args_0:0\", shape=(32, 32, 3), dtype=uint8) Tensor(\"args_1:0\", shape=(1,), dtype=uint8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KhFeQDqxLwf"
      },
      "source": [
        "def _forward(batch, is_training):\n",
        "  \"\"\"Forward application of the resnet.\"\"\"\n",
        "  images = batch['images']\n",
        "  net = hk.nets.ResNet18(10,\n",
        "                         resnet_v2=True,\n",
        "                         bn_config={'decay_rate': 0.9})\n",
        "  return net(images, is_training=is_training)\n",
        "\n",
        "# Transform our forwards function into a pair of pure functions.\n",
        "forward = hk.transform_with_state(_forward)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zeupz_fxMjg"
      },
      "source": [
        "def make_optimizer():\n",
        "  \"\"\"SGD with momentum and a fixed lr.\"\"\"\n",
        "  return optax.chain(\n",
        "      optax.trace(decay=0.9, nesterov=False), #momentum\n",
        "      optax.scale(-1e-3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3RD92rVKjS0"
      },
      "source": [
        "def l2_loss(params):\n",
        "  return 0.5 * sum(jnp.sum(jnp.square(p)) for p in params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNxuZutyT8E3"
      },
      "source": [
        "class TrainState(NamedTuple):\n",
        "  params: hk.Params\n",
        "  state: hk.State\n",
        "  opt_state: optax.OptState"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Fa7K3uYKq55"
      },
      "source": [
        "def loss_fn(params, state, batch):\n",
        "  \"\"\"Computes a regularized loss for the given batch.\"\"\"\n",
        "  logits, state = forward.apply(params, state, None, batch, is_training=True)\n",
        "  labels = jax.nn.one_hot(batch['labels'], 10)\n",
        "  loss = optax.softmax_cross_entropy(logits=logits, labels=labels).mean()\n",
        "  l2_params = [p for ((mod_name, _), p) in tree.flatten_with_path(params)\n",
        "               if 'batchnorm' not in mod_name]\n",
        "  loss = loss + 1e-4 * l2_loss(l2_params)\n",
        "  return loss, (loss, state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9gMoV9tMm3n"
      },
      "source": [
        "@jax.jit\n",
        "def train_step(train_state, batch):\n",
        "  \"\"\"Applies an update to parameters and returns new state.\"\"\"\n",
        "  params, state, opt_state = train_state\n",
        "  grads, (loss, new_state) = (\n",
        "      jax.grad(loss_fn, has_aux=True)(params, state, batch))\n",
        "  \n",
        "  # Compute and apply updates via our optimizer.\n",
        "  updates, new_opt_state = make_optimizer().update(grads, opt_state)\n",
        "  new_params = optax.apply_updates(params, updates)\n",
        "\n",
        "  train_state = TrainState(new_params, new_state, new_opt_state)\n",
        "  return train_state, loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrrhZnVoTi8Q"
      },
      "source": [
        "def initial_state(rng, batch):\n",
        "  \"\"\"Computes the initial network state.\"\"\"\n",
        "  params, state = forward.init(rng, batch, is_training=True)\n",
        "  opt_state = make_optimizer().init(params)\n",
        "  return TrainState(params, state, opt_state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lx_R2aX6T5J5"
      },
      "source": [
        "epochs = 5\n",
        "rng = jax.random.PRNGKey(0)\n",
        "batch = next(iter(ds_numpy))\n",
        "train_state = initial_state(rng, batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9j2TuUIahfR",
        "outputId": "cca513f6-6cc3-4891-8cf7-8b8cdec0a26a"
      },
      "source": [
        "for _ in range(epochs):\n",
        "  total_losses = []\n",
        "  for batch in ds_numpy:\n",
        "    train_state, loss = train_step(train_state, batch)\n",
        "    total_losses.append(loss)\n",
        "  print(sum(total_losses)/len(total_losses))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.484259\n",
            "1.2876029\n",
            "1.1279528\n",
            "0.98609024\n",
            "0.8480268\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}